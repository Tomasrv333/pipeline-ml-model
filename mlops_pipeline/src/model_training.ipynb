{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b58dfa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formas de los conjuntos:\n",
      "X_train: (1600, 4)\n",
      "y_train: (1600,)\n",
      "X_test: (400, 4)\n",
      "y_test: (400,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ”¹ Cargar datos ya procesados\n",
    "# ============================================================\n",
    "base_path = '../data'\n",
    "\n",
    "X_train = np.load(f'{base_path}/X_train.npy', allow_pickle=True)\n",
    "X_test = np.load(f'{base_path}/X_test.npy', allow_pickle=True)\n",
    "y_train = np.load(f'{base_path}/y_train.npy', allow_pickle=True)\n",
    "y_test = np.load(f'{base_path}/y_test.npy', allow_pickle=True)\n",
    "\n",
    "print(\"Formas de los conjuntos:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)\n",
    "\n",
    "# Convertir y_train / y_test a vectores planos si no lo estÃ¡n\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ed609e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Entrenando modelo: LogisticRegression...\n",
      "LogisticRegression â†’ Accuracy train: 0.898 | test: 0.938\n",
      "LogisticRegression â†’ F1 train: 0.884 | test: 0.928\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸš€ Entrenando modelo: RandomForest...\n",
      "RandomForest â†’ Accuracy train: 0.949 | test: 0.963\n",
      "RandomForest â†’ F1 train: 0.944 | test: 0.958\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸš€ Entrenando modelo: XGBoost...\n",
      "XGBoost â†’ Accuracy train: 0.994 | test: 0.980\n",
      "XGBoost â†’ F1 train: 0.993 | test: 0.977\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ðŸ”¹ Entrenar modelos\n",
    "# ============================================================\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, C=0.8, solver='lbfgs'),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=4, random_state=42\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        max_depth=3, learning_rate=0.1, n_estimators=100,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        eval_metric='logloss', random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nðŸš€ Entrenando modelo: {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    acc_train = accuracy_score(y_train, y_pred_train)\n",
    "    acc_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "    f1_train = f1_score(y_train, y_pred_train)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "    print(f\"{name} â†’ Accuracy train: {acc_train:.3f} | test: {acc_test:.3f}\")\n",
    "    print(f\"{name} â†’ F1 train: {f1_train:.3f} | test: {f1_test:.3f}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "215a9620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š ValidaciÃ³n cruzada (5-Fold) â€” Evaluando robustez...\n",
      "LogisticRegression â†’ Accuracy promedio (CV=5): 0.896 Â± 0.021\n",
      "RandomForest â†’ Accuracy promedio (CV=5): 0.941 Â± 0.012\n",
      "XGBoost â†’ Accuracy promedio (CV=5): 0.973 Â± 0.007\n",
      "\n",
      "âœ… Modelos entrenados y guardados correctamente.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ“Š ValidaciÃ³n cruzada (5-Fold) â€” Evaluando robustez...\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"{name} â†’ Accuracy promedio (CV=5): {scores.mean():.3f} Â± {scores.std():.3f}\")\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ”¸ 5. Guardar modelos entrenados\n",
    "# ============================================================\n",
    "joblib.dump(models[\"LogisticRegression\"], \"../data/best_model_logreg.pkl\")\n",
    "joblib.dump(models[\"RandomForest\"], \"../data/best_model_rf.pkl\")\n",
    "joblib.dump(models[\"XGBoost\"], \"../data/best_model_xgb.pkl\")\n",
    "\n",
    "print(\"\\nâœ… Modelos entrenados y guardados correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_pipeline-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
